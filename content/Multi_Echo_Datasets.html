
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Open Multi-Echo Datasets &#8212; Multi-Echo fMRI Data Analysis</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Acquiring Multi-Echo Data" href="Acquiring_Multi_Echo_Data.html" />
    <link rel="prev" title="Generate tedana walkthrough figures" href="plot_approach_figures.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Multi-Echo fMRI Data Analysis</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Multi-Echo (fMRI) Data Analysis
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Course_Overview.html">
   Course Overview
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00_Download_Data.html">
   Download Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Install_Software.html">
   Install Software
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Recommended_Reading.html">
   Recommended Reading
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Theoretical Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="MR_Physics.html">
   MR Physics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fMRI_Sequences.html">
   Multi-Echo fMRI Sequences
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Decay.html">
   Signal Decay
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="TE_Dependence.html">
   BOLD, non-BOLD, and TE-dependence with tedana
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_approach_figures.html">
   Generate tedana walkthrough figures
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Practical Resources
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Open Multi-Echo Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Acquiring_Multi_Echo_Data.html">
   Acquiring Multi-Echo Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Processing_Multi_Echo_Data.html">
   Processing Multi-Echo Data
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Analysis Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_Optimal_Combination_with_t2smap.html">
   Optimal combination with
   <code class="docutils literal notranslate">
    <span class="pre">
     t2smap
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_Volume-wise_T2star_estimation_with_t2smap.html">
   Volume-wise T2*/S0 estimation with
   <code class="docutils literal notranslate">
    <span class="pre">
     t2smap
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_Denoising_with_tedana.html">
   Multi-Echo Denoising with
   <code class="docutils literal notranslate">
    <span class="pre">
     tedana
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_Dual_Echo_Denoising.html">
   Dual-Echo Denoising with
   <code class="docutils literal notranslate">
    <span class="pre">
     nilearn
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_3dMEPFM.html">
   Model-free deconvolution with
   <code class="docutils literal notranslate">
    <span class="pre">
     pySPFM
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_Cerebrovascular_Reactivity_Mapping.html">
   Cerebrovascular Reactivity Mapping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_Manual_Classification_with_rica.html">
   Manual Classification with
   <code class="docutils literal notranslate">
    <span class="pre">
     rica
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_ICA_Based_Denoising.html">
   Denoising Data with ICA
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Final Thoughts
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="build_information.html">
   Build Information
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="glossary.html">
   Glossary
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ME-ICA/multi-echo-data-analysis/main?urlpath=tree/content/content/Multi_Echo_Datasets.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ME-ICA/multi-echo-data-analysis"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ME-ICA/multi-echo-data-analysis/issues/new?title=Issue%20on%20page%20%2Fcontent/Multi_Echo_Datasets.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/content/Multi_Echo_Datasets.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../_sources/content/Multi_Echo_Datasets.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multi-echo-fmri-replication-sample-of-autobiographical-memory-prospection-and-theory-of-mind-reasoning-tasks">
   Multi-echo fMRI replication sample of autobiographical memory, prospection and theory of mind reasoning tasks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multi-echo-cambridge">
   Multi-echo Cambridge
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiband-multi-echo-imaging-of-simultaneous-oxygenation-and-flow-timeseries-for-resting-state-connectivity">
   Multiband multi-echo imaging of simultaneous oxygenation and flow timeseries for resting state connectivity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#valence-processing-differs-across-stimulus-modalities">
   Valence processing differs across stimulus modalities
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cambridge-centre-for-ageing-neuroscience-cam-can">
   Cambridge Centre for Ageing Neuroscience (Cam-CAN)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rt-me-fmri-a-task-and-resting-state-dataset-for-real-time-multi-echo-fmri-methods-development-and-validation">
   rt-me-fMRI - A task and resting state dataset for real-time, multi-echo fMRI methods development and validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#euskalibur">
   EuskalIBUR
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#le-petit-prince">
   Le Petit Prince
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neurocognitive-aging-data-release-with-behavioral-structural-and-multi-echo-functional-mri-measures">
   Neurocognitive aging data release with behavioral, structural, and multi-echo functional MRI measures
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Open Multi-Echo Datasets</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multi-echo-fmri-replication-sample-of-autobiographical-memory-prospection-and-theory-of-mind-reasoning-tasks">
   Multi-echo fMRI replication sample of autobiographical memory, prospection and theory of mind reasoning tasks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multi-echo-cambridge">
   Multi-echo Cambridge
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiband-multi-echo-imaging-of-simultaneous-oxygenation-and-flow-timeseries-for-resting-state-connectivity">
   Multiband multi-echo imaging of simultaneous oxygenation and flow timeseries for resting state connectivity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#valence-processing-differs-across-stimulus-modalities">
   Valence processing differs across stimulus modalities
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cambridge-centre-for-ageing-neuroscience-cam-can">
   Cambridge Centre for Ageing Neuroscience (Cam-CAN)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rt-me-fmri-a-task-and-resting-state-dataset-for-real-time-multi-echo-fmri-methods-development-and-validation">
   rt-me-fMRI - A task and resting state dataset for real-time, multi-echo fMRI methods development and validation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#euskalibur">
   EuskalIBUR
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#le-petit-prince">
   Le Petit Prince
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neurocognitive-aging-data-release-with-behavioral-structural-and-multi-echo-functional-mri-measures">
   Neurocognitive aging data release with behavioral, structural, and multi-echo functional MRI measures
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="open-multi-echo-datasets">
<span id="content-open-datasets"></span><h1>Open Multi-Echo Datasets<a class="headerlink" href="#open-multi-echo-datasets" title="Permalink to this headline">#</a></h1>
<p>A number of multi-echo datasets have been made public so far.
This list is not necessarily up to date, so please check out OpenNeuro to potentially find more.</p>
<div class="section" id="multi-echo-fmri-replication-sample-of-autobiographical-memory-prospection-and-theory-of-mind-reasoning-tasks">
<h2>Multi-echo fMRI replication sample of autobiographical memory, prospection and theory of mind reasoning tasks<a class="headerlink" href="#multi-echo-fmri-replication-sample-of-autobiographical-memory-prospection-and-theory-of-mind-reasoning-tasks" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://openneuro.org/datasets/ds000210">https://openneuro.org/datasets/ds000210</a></p>
<p><strong>Citation</strong>: <span id="id1">DuPre <em>et al.</em> [<a class="reference internal" href="bibliography.html#id15" title="Elizabeth DuPre, Wen-Ming Luh, and R Nathan Spreng. Multi-echo fmri replication sample of autobiographical memory, prospection and theory of mind reasoning tasks. Scientific data, 3(1):1–9, 2016.">2016</a>]</span></p>
<p><strong>Brief Description</strong>: 31 participants, with one run of resting-state and four runs of cued SGT task.
The multi-echo fMRI data have three echoes (13, 27, 43 ms).
Additional data include T1-weighted anatomical scans and physiological data (chest belt and PPG)
recorded concurrently with the fMRI scans.</p>
</div>
<div class="section" id="multi-echo-cambridge">
<h2>Multi-echo Cambridge<a class="headerlink" href="#multi-echo-cambridge" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://openneuro.org/datasets/ds000258">https://openneuro.org/datasets/ds000258</a></p>
<p><strong>Citation</strong>: <span id="id2">Kundu <em>et al.</em> [<a class="reference internal" href="bibliography.html#id11" title="P Kundu, N D Brenowitz, V Voon, Y Worbe, P E Vertes, S J Inati, Z S Saad, P A Bandettini, and E T Bullmore. Integrated strategy for improving functional connectivity mapping using multiecho fMRI. Proceedings of the National Academy of Sciences, 110(40):16187–16192, 2013.">2013</a>]</span></p>
<p><strong>Brief Description</strong>: 89 participants, with one run of resting-state.
The multi-echo fMRI data have four echoes (12, 28, 44, 60 ms).
Additional data include T1-weighted anatomical scans.</p>
</div>
<div class="section" id="multiband-multi-echo-imaging-of-simultaneous-oxygenation-and-flow-timeseries-for-resting-state-connectivity">
<h2>Multiband multi-echo imaging of simultaneous oxygenation and flow timeseries for resting state connectivity<a class="headerlink" href="#multiband-multi-echo-imaging-of-simultaneous-oxygenation-and-flow-timeseries-for-resting-state-connectivity" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://openneuro.org/datasets/ds000254">https://openneuro.org/datasets/ds000254</a></p>
<p><strong>Citation</strong>: <span id="id3">Cohen and Wang [<a class="reference internal" href="bibliography.html#id6" title="Alexander D Cohen and Yang Wang. Improving the assessment of breath-holding induced cerebral vascular reactivity using a multiband multi-echo asl/bold sequence. Scientific reports, 9(1):1–12, 2019.">2019</a>]</span></p>
<p><strong>Brief Description</strong>: 13 participants, with one run of bilateral finger-tapping task.
The multi-echo fMRI data have four echoes (9.1, 25, 39.6, 54.3 ms).
Additional data include T1-weighted anatomical scans and pCASL acquired concurrently with the fMRI scans.</p>
</div>
<div class="section" id="valence-processing-differs-across-stimulus-modalities">
<h2>Valence processing differs across stimulus modalities<a class="headerlink" href="#valence-processing-differs-across-stimulus-modalities" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://openneuro.org/datasets/ds001491">https://openneuro.org/datasets/ds001491</a></p>
<p><strong>Citation</strong>: <span id="id4">Dalenberg <em>et al.</em> [<a class="reference internal" href="bibliography.html#id14" title="Jelle R. Dalenberg, Liselore Weitkamp, Remco J. Renken, and Gert J. ter Horst. Valence processing differs across stimulus modalities. NeuroImage, 183:734-744, 2018. URL: https://www.sciencedirect.com/science/article/pii/S1053811918307572, doi:https://doi.org/10.1016/j.neuroimage.2018.08.059.">2018</a>]</span></p>
<p><strong>Brief Description</strong>: 20 participants, with one run of image-viewing and four runs of flavor-experiencing task.
The multi-echo fMRI data have three echoes (8.02, 22.03, 36.03 ms).
Additional data include T1-weighted anatomical scans.</p>
</div>
<div class="section" id="cambridge-centre-for-ageing-neuroscience-cam-can">
<h2>Cambridge Centre for Ageing Neuroscience (Cam-CAN)<a class="headerlink" href="#cambridge-centre-for-ageing-neuroscience-cam-can" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/">https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/</a></p>
<p><strong>Citation</strong>: <span id="id5">Shafto <em>et al.</em> [<a class="reference internal" href="bibliography.html#id12" title="Meredith A Shafto, Cam-CAN, Lorraine K Tyler, Marie Dixon, Jason R Taylor, James B Rowe, Rhodri Cusack, Andrew J Calder, William D Marslen-Wilson, John Duncan, Tim Dalgleish, Richard N Henson, Carol Brayne, and Fiona E Matthews. The cambridge centre for ageing and neuroscience (Cam-CAN) study protocol: a cross-sectional, lifespan, multidisciplinary examination of healthy cognitive ageing. BMC Neurology, 2014.">2014</a>]</span></p>
<p><strong>Brief Description</strong>: The Cam-CAN MRI dataset is part of the much larger Cam-CAN research project.
649 participants completed the MRI scanning protocol with multi-echo fMRI data.
There is one run of multi-echo fMRI data, using a movie-watching task.
The multi-echo fMRI data have five echoes (9.4, 21.23, 33.06, 44.89, 56.72 ms).
Additional data include T1-weighted anatomical scans, T2-weighted anatomical scans,
diffusion-weighted scans, magnetization transfer scans, one run of single-echo,
resting-state fMRI, and one run of single-echo, sensorimotor task fMRI.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Accessing this dataset requires a data access application.</p>
</div>
</div>
<div class="section" id="rt-me-fmri-a-task-and-resting-state-dataset-for-real-time-multi-echo-fmri-methods-development-and-validation">
<h2>rt-me-fMRI - A task and resting state dataset for real-time, multi-echo fMRI methods development and validation<a class="headerlink" href="#rt-me-fmri-a-task-and-resting-state-dataset-for-real-time-multi-echo-fmri-methods-development-and-validation" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://doi.org/10.34894/R1TNL8">https://doi.org/10.34894/R1TNL8</a></p>
<p><strong>Citation</strong>: <span id="id6">Heunis <em>et al.</em> [<a class="reference internal" href="bibliography.html#id3" title="Stephan Heunis, Marcel Breeuwer, César Caballero-Gaudes, Lydia Hellrung, Willem Huijbers, Jacobus FA Jansen, Rolf Lamerichs, Svitlana Zinger, and Albert P Aldenkamp. The effects of multi-echo fmri combination and rapid t2*-mapping on offline and real-time bold sensitivity. NeuroImage, 238:118244, 2021. URL: https://www.sciencedirect.com/science/article/pii/S1053811921005218, doi:https://doi.org/10.1016/j.neuroimage.2021.118244.">2021</a>]</span></p>
<p><strong>Brief Description</strong>: 28 participants, with one run of resting-state,
one run of emotion-processing task, one run of imagined emotion-processing task,
one run of finger-tapping task, and one run of imagined finger-tapping task.
The multi-echo fMRI data have three echoes (14, 28, 42 ms).
Additional data include T1-weighted anatomical scans and physiological data (chest belt and cardiac)
acquired concurrently with the fMRI scans.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Accessing this dataset requires a data access application.</p>
</div>
</div>
<div class="section" id="euskalibur">
<h2>EuskalIBUR<a class="headerlink" href="#euskalibur" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://openneuro.org/datasets/ds003192">https://openneuro.org/datasets/ds003192</a></p>
<p><strong>Citation</strong>: <span id="id7">Moia <em>et al.</em> [<a class="reference internal" href="bibliography.html#id5" title="Stefano Moia, Maite Termenon, Eneko Uruñuela, Gang Chen, Rachael C. Stickland, Molly G. Bright, and César Caballero-Gaudes. Ica-based denoising strategies in breath-hold induced cerebrovascular reactivity mapping with multi echo bold fmri. NeuroImage, 233:117914, 2021. URL: https://www.sciencedirect.com/science/article/pii/S1053811921001919, doi:https://doi.org/10.1016/j.neuroimage.2021.117914.">2021</a>]</span></p>
<p><strong>Brief Description</strong>: 7 participants with 10 sessions each, with one run of breath-holding task.
The multi-echo fMRI data have five echoes (10.6, 28.69, 46.78, 64.87, 82.96 ms).
Additional data include T1-weighted anatomical scans and physiological data (chest belt, cardiac, exhaled CO2, exhaled O2)
acquired concurrently with the fMRI scans.</p>
</div>
<div class="section" id="le-petit-prince">
<h2>Le Petit Prince<a class="headerlink" href="#le-petit-prince" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://openneuro.org/datasets/ds003643">https://openneuro.org/datasets/ds003643</a></p>
<p><strong>Citation</strong>: <span id="id8">Li <em>et al.</em> [<a class="reference internal" href="bibliography.html#id13" title="Jixing Li, Shohini Bhattasali, Shulin Zhang, Berta Franzluebbers, Wen-Ming Luh, R. Nathan Spreng, Jonathan R. Brennan, Yiming Yang, Christophe Pallier, and John Hale. Le petit prince: a multilingual fmri corpus using ecological stimuli. bioRxiv, 2021. URL: https://www.biorxiv.org/content/early/2021/10/04/2021.10.02.462875, arXiv:https://www.biorxiv.org/content/early/2021/10/04/2021.10.02.462875.full.pdf, doi:10.1101/2021.10.02.462875.">2021</a>]</span></p>
<p><strong>Brief Description</strong>: 111 participants, with nine runs of an auditory narrative task.
The multi-echo fMRI data have three echoes, with some participants having TEs of 12.8, 27.5, and 43 ms
and others having 10, 25, and 38 ms.
Additional data include T1-weighted anatomical scans.</p>
<p>The auditory narrative task involves listening to Le Petit Prince in nine 10-minute runs, totally around 90 minutes.
Given the naturalistic nature of this task, it is a good target for functional alignment analyses.</p>
<p>Additionally, the language in which the task was presented differed across participants.
51 participants listened to the audiobook in English, 35 listened in Chinese, and 30 listened in French.</p>
</div>
<div class="section" id="neurocognitive-aging-data-release-with-behavioral-structural-and-multi-echo-functional-mri-measures">
<h2>Neurocognitive aging data release with behavioral, structural, and multi-echo functional MRI measures<a class="headerlink" href="#neurocognitive-aging-data-release-with-behavioral-structural-and-multi-echo-functional-mri-measures" title="Permalink to this headline">#</a></h2>
<p><strong>Link</strong>: <a class="reference external" href="https://openneuro.org/datasets/ds003592">https://openneuro.org/datasets/ds003592</a></p>
<p><strong>Citation</strong>: <span id="id9">Spreng <em>et al.</em> [<a class="reference internal" href="bibliography.html#id16" title="RN Spreng, R Setton, U Alter, BN Cassidy, B Darboh, E DuPre, K Kantarovich, AW Lockrow, L Mwilambwe-Tshilobo, WM Luh, and others. Neurocognitive aging data release with behavioral, structural and multi-echo functional mri measures. Scientific Data, 2022. URL: https://doi.org/10.1038/s41597-022-01231-7, doi:10.1038/s41597-022-01231-7.">2022</a>]</span></p>
<p><strong>Brief Description</strong>: 301 participants, with two 10-minute resting-state runs.
The multi-echo fMRI data have three echoes (13.7, 30, 47 ms).
Additional data include T1-weighted anatomical scans, FLAIR anatomical scans, and
physiological data (chest belt, cardiac) acquired concurrently with the fMRI scans.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="plot_approach_figures.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Generate tedana walkthrough figures</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Acquiring_Multi_Echo_Data.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Acquiring Multi-Echo Data</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The tedana community<br/>
  
      &copy; Copyright 2021.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>