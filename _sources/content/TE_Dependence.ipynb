{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8cbd08e",
   "metadata": {},
   "source": [
    "# BOLD, non-BOLD, and TE-dependence with tedana\n",
    "\n",
    "```{important}\n",
    "This chapter should differentiate itself from Signal_Decay by focusing on the application of {eq}`monoexponential_decay`\n",
    "to decompositions, rather than raw signal compared between active and inactive states.\n",
    "\n",
    "We may want to describe adaptive masking, data whitening, the model fit metrics, and post-processing methods (e.g., MIR)\n",
    "in this page as well.\n",
    "```\n",
    "\n",
    "```{important}\n",
    "The general flow of this chapter should be:\n",
    "\n",
    "1.  Explain the monoexponential decay equation, but primarily reference back to Signal_Decay.\n",
    "2.  Walk through optimal combination and adaptive masking somewhere around here.\n",
    "3.  Describe why multi-echo denoising can't be done directly to the raw signal and why ICA is necessary.\n",
    "    1.  This mean talking about noise, really, and why the FIT method (volume-wise T2*/S0 estimation)\n",
    "        is generally considered too noisy for practical application.\n",
    "    2.  Walk through TEDPCA as well.\n",
    "4.  The TE-(in)dependence models.\n",
    "5.  Apply the models to a simulated component, as well as multiple real components.\n",
    "    1.  Show model fit for different components.\n",
    "6.  Compare optimally combined, denoised, and high-kappa data.\n",
    "7.  Describe post-processing methods, like minimum image regression and tedana's version of global signal regression.\n",
    "```\n",
    "\n",
    "This notebook uses simulated T2*/S0 manipulations to show how TE-dependence is leveraged to denoise multi-echo data.\n",
    "\n",
    "The equation for how signal is dependent on changes in S0 and T2*:\n",
    "\n",
    "```{math}\n",
    ":label: monoexponential_decay\n",
    "S(t, TE_k) = \\bar{S}(TE_k) * (1 + \\frac{{\\Delta}{S_0}(t)}{\\bar{S}_0} - {\\Delta}{R_2^*}(t)*TE_k)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b849e78",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Log' from 'distutils.log' (/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/setuptools/_distutils/log.py). Module \"sklearn\" could not be found. See http://nilearn.github.io/introduction.html#installation for installation information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbook_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_te_dependence_statistics, predict_bold_signal\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmyst_nb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glue\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m first_level\n",
      "File \u001b[0;32m~/work/multi-echo-data-analysis/multi-echo-data-analysis/content/book_utils.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Utility functions for the JupyterBook.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image, masking\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregress_one_image_out_of_another\u001b[39m(data_img, nuis_img, mask_img):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124;03m\"\"\"Do what it says on the tin.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nilearn/__init__.py:68\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info\u001b[38;5;241m.\u001b[39mminor \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m:\n\u001b[1;32m     65\u001b[0m         _py36_deprecation_warning()\n\u001b[0;32m---> 68\u001b[0m \u001b[43m_check_module_dependencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m _python_deprecation_warnings()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Monkey-patch gzip to have faster reads on large gzip files\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nilearn/version.py:180\u001b[0m, in \u001b[0;36m_check_module_dependencies\u001b[0;34m(is_nilearn_installing)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (module_name, module_metadata) \u001b[38;5;129;01min\u001b[39;00m REQUIRED_MODULE_METADATA:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_nilearn_installing \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m module_metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequired_at_installation\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;66;03m# Skip check only when installing and it's a module that\u001b[39;00m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# will be auto-installed.\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m         \u001b[43m_import_module_with_version_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[43mminimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_metadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_version\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43minstall_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall_info\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/nilearn/version.py:72\u001b[0m, in \u001b[0;36m_import_module_with_version_check\u001b[0;34m(module_name, minimum_version, install_info)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"Check that module is installed with a recent enough version.\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     74\u001b[0m     user_friendly_info \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m could not be found. \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     75\u001b[0m         module_name,\n\u001b[1;32m     76\u001b[0m         install_info \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease install it properly to use nilearn.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m ]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/sklearn/base.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     _DEFAULT_TAGS,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/sklearn/utils/__init__.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version, threadpool_info\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     as_float_array,\n\u001b[1;32m     33\u001b[0m     assert_all_finite,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     check_scalar,\n\u001b[1;32m     42\u001b[0m )\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/sklearn/utils/fixes.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreadpoolctl\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/scipy/stats/__init__.py:467\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m \n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    466\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/scipy/stats/_stats_py.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyVersion\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _measurements\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/numpy/testing/__init__.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_assert_valid_refcount, _gen_alignment_data)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extbuild, decorators \u001b[38;5;28;01mas\u001b[39;00m dec\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnosetester\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     run_module_suite, NoseTester \u001b[38;5;28;01mas\u001b[39;00m Tester\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     17\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m _private\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m__all__ \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTestCase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_module_suite\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/numpy/testing/_private/extbuild.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msysconfig\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mccompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m new_compiler\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompileError\n\u001b[1;32m     14\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuild_and_import_extension\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompile_extension_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/numpy/distutils/__init__.py:24\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mAn enhanced distutils, providing support for Fortran compilers, for BLAS,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mLAPACK and other common libraries for numerical computing, and more.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Must import local ccompiler ASAP in order to get\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# customized CCompiler.spawn effective.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ccompiler\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unixccompiler\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnpy_pkg_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/numpy/distutils/ccompiler.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msysconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m customize_compiler\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LooseVersion\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexec_command\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     filepath_from_subprocess_output, forward_bytes_to_stdout\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cyg2win32, is_sequence, mingw32, \\\n\u001b[1;32m     25\u001b[0m                                       get_num_build_jobs, \\\n\u001b[1;32m     26\u001b[0m                                       _commandline_dep_string, \\\n\u001b[1;32m     27\u001b[0m                                       sanitize_cxx_flags\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/numpy/distutils/log.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Log \u001b[38;5;28;01mas\u001b[39;00m old_Log\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _global_log\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (red_text, default_text, cyan_text,\n\u001b[1;32m      8\u001b[0m         green_text, is_sequence, is_string)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Log' from 'distutils.log' (/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/setuptools/_distutils/log.py). Module \"sklearn\" could not be found. See http://nilearn.github.io/introduction.html#installation for installation information."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from book_utils import compute_te_dependence_statistics, predict_bold_signal\n",
    "from myst_nb import glue\n",
    "from nilearn.glm import first_level\n",
    "from repo2data.repo2data import Repo2Data\n",
    "from scipy import signal, stats\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Install the data if running locally, or point to cached data if running on neurolibre\n",
    "DATA_REQ_FILE = os.path.join(\"../binder/data_requirement.json\")\n",
    "\n",
    "# Download data\n",
    "repo2data = Repo2Data(DATA_REQ_FILE)\n",
    "data_path = repo2data.install()\n",
    "data_path = os.path.abspath(os.path.join(data_path[0], \"data\"))\n",
    "\n",
    "out_dir = os.path.join(data_path, \"te-dependence\")\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785ea48",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "# For a nice, smooth curve\n",
    "echo_times = np.arange(0, 201, 1)\n",
    "\n",
    "n_echoes = len(echo_times)\n",
    "pal = sns.color_palette(\"cubehelix\", 8)\n",
    "\n",
    "mean_s0 = 16000\n",
    "mean_t2s = 30\n",
    "\n",
    "frac = 0.2\n",
    "s02 = mean_s0 + (mean_s0 * frac)\n",
    "t2s2 = mean_t2s + (mean_t2s * frac)\n",
    "\n",
    "mean_sig = np.squeeze(predict_bold_signal(echo_times, mean_s0, mean_t2s))\n",
    "\n",
    "# Signal with fluctuating S0\n",
    "sig2 = np.squeeze(predict_bold_signal(echo_times, s02, mean_t2s))\n",
    "d_sig2 = sig2 - mean_sig\n",
    "dt_sig2 = d_sig2 / ((sig2 + mean_sig) / 2.0)\n",
    "\n",
    "# Signal with fluctuating T2*\n",
    "sig3 = np.squeeze(predict_bold_signal(echo_times, mean_s0, t2s2))\n",
    "d_sig3 = sig3 - mean_sig\n",
    "dt_sig3 = d_sig3 / ((sig3 + mean_sig) / 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366c805",
   "metadata": {},
   "source": [
    "## Plot simulations of BOLD and non-BOLD signals as a function of echo time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62077c",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# change s0\n",
    "fig, axes = plt.subplots(3, 2, sharex=True, figsize=(16, 6))\n",
    "axes[0, 0].yaxis.tick_right()\n",
    "axes[0, 0].set_xticklabels([])\n",
    "axes[0, 0].plot(echo_times, mean_sig, \"red\", label=\"Mean signal\")\n",
    "axes[0, 0].plot(echo_times, sig2, \"blue\", label=\"Timepoint's signal\")\n",
    "axes[0, 0].set_ylim(0)\n",
    "axes[0, 0].set_title(\"Change in S0\", fontsize=20, y=1.02)\n",
    "axes[0, 0].set_ylabel(\n",
    "    \"Signal\\n$S(TE_n)$\", fontsize=16, rotation=0, labelpad=40, va=\"center\"\n",
    ")\n",
    "leg = axes[0, 0].legend()\n",
    "\n",
    "axes[1, 0].yaxis.tick_right()\n",
    "axes[1, 0].set_xticklabels([])\n",
    "axes[1, 0].plot(echo_times, d_sig2, \"red\")\n",
    "axes[1, 0].set_ylim(0)\n",
    "axes[1, 0].set_ylabel(\n",
    "    \"${\\\\Delta}S(TE_n)$\", fontsize=16, rotation=0, labelpad=40, va=\"center\"\n",
    ")\n",
    "\n",
    "# No slope, intercept at delta(S0)/mean(S0)\n",
    "axes[2, 0].yaxis.tick_right()\n",
    "axes[2, 0].plot(echo_times, dt_sig2, \"red\")\n",
    "axes[2, 0].set_ylabel(\n",
    "    \"$\\\\frac{{\\\\Delta}S(TE_n)}{\\\\bar{S}(TE_n)}$\",\n",
    "    fontsize=24,\n",
    "    rotation=0,\n",
    "    labelpad=40,\n",
    "    va=\"center\",\n",
    ")\n",
    "axes[2, 0].set_xlabel(\"Echo Time (ms)\", fontsize=16)\n",
    "\n",
    "# change t2s\n",
    "# max diff is between orig and new T2*, but is definitely not mean\n",
    "max_diff_te = echo_times[d_sig3 == np.max(d_sig3)][0]\n",
    "\n",
    "axes[0, 1].yaxis.tick_right()\n",
    "axes[0, 1].set_xticklabels([])\n",
    "axes[0, 1].plot(echo_times, mean_sig, \"red\", label=\"Mean signal\")\n",
    "axes[0, 1].plot(echo_times, sig3, \"blue\", label=\"Timepoint's signal\")\n",
    "axes[0, 1].set_ylim(0)\n",
    "axes[0, 1].set_title(\"Change in T2*\", fontsize=20, y=1.02)\n",
    "\n",
    "# Plot important echo times\n",
    "axes[0, 1].axvline(mean_t2s, color=\"green\", alpha=0.5)\n",
    "axes[0, 1].axvline(max_diff_te, color=\"gray\", alpha=0.5)\n",
    "axes[0, 1].axvline(t2s2, color=\"orange\", alpha=0.5)\n",
    "leg = axes[0, 1].legend()\n",
    "\n",
    "axes[1, 1].yaxis.tick_right()\n",
    "axes[1, 1].set_xticklabels([])\n",
    "axes[1, 1].plot(echo_times, d_sig3, \"red\")\n",
    "axes[1, 1].set_ylim(0)\n",
    "\n",
    "# Plot important echo times\n",
    "axes[1, 1].axvline(mean_t2s, label=\"T2* of mean data\", color=\"green\", alpha=0.5)\n",
    "axes[1, 1].axvline(\n",
    "    max_diff_te, label=\"TE of maximized contrast\", color=\"gray\", alpha=0.5\n",
    ")\n",
    "axes[1, 1].axvline(t2s2, label=\"T2* of timepoint's data\", color=\"orange\", alpha=0.5)\n",
    "leg = axes[1, 1].legend()\n",
    "\n",
    "pred_slope = (dt_sig3[-1] - dt_sig3[0]) / (echo_times[-1] - echo_times[0])\n",
    "pred_int = (pred_slope * echo_times[-1]) - dt_sig3[-1]\n",
    "pred_max = pred_slope * echo_times[-1]\n",
    "\n",
    "axes[2, 1].yaxis.tick_right()\n",
    "axes[2, 1].plot(echo_times, dt_sig3, \"red\")\n",
    "axes[2, 1].plot(\n",
    "    [0, echo_times[-1]],\n",
    "    [pred_int, pred_max],\n",
    "    \"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Theoretical line\",\n",
    ")\n",
    "axes[2, 1].set_ylim(0, None)\n",
    "axes[2, 1].set_xlim(0, np.max(echo_times))\n",
    "# axes[2, 1].set_xticks(echo_times)\n",
    "axes[2, 1].set_xlabel(\"Echo Time (ms)\", fontsize=16)\n",
    "axes[2, 1].axvline(max_diff_te, color=\"gray\", alpha=0.5)\n",
    "axes[2, 1].axvline(mean_t2s, color=\"green\", alpha=0.5)\n",
    "axes[2, 1].axvline(t2s2, color=\"orange\", alpha=0.5)\n",
    "leg = axes[2, 1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "glue(\"fig_bold_nonbold_simulations\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9b087",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_bold_nonbold_simulations\n",
    ":name: fig_bold_nonbold_simulations\n",
    ":align: center\n",
    "\n",
    "Simulations of BOLD and non-BOLD signals as a function of echo time\n",
    "```\n",
    "\n",
    "## Make design matrices\n",
    "\n",
    "For TEDPCA and TEDICA, we use regression to get parameter estimates (PEs; not beta values)\n",
    "for component time-series against echo-specific data, and substitute those PEs for ${\\bar{S}(TE_k)}$.\n",
    "At some point, I would like to dig into why those parameter estimates are equivalent to ${\\bar{S}(TE_k)}$ for our purposes.\n",
    "\n",
    "## TE-independence model\n",
    "\n",
    "```{math}\n",
    ":label: te_independence_model1\n",
    "\\frac{{\\Delta}S(TE_k)}{\\bar{S(TE_k)}} = \\frac{{\\Delta}S_0}{S_0}\n",
    "```\n",
    "\n",
    "```{math}\n",
    ":label: te_independence_model2\n",
    "{\\Delta}S(TE_k) = {\\bar{S}(TE_k)}\\frac{{\\Delta}S_0}{S_0}\n",
    "```\n",
    "\n",
    "$\\frac{{\\Delta}S_0}{S_0}$ is a scalar (i.e., doesn't change with TE), so we ignore that,\n",
    "which means we only use ${\\bar{S}(TE_k)}$ (mean echo-wise signal).\n",
    "\n",
    "Thus,\n",
    "\n",
    "```{math}\n",
    ":label: te_independence_model3\n",
    "{\\Delta}S(TE_k) = {\\bar{S}(TE_k)} * X\n",
    "```\n",
    "\n",
    "and for TEDPCA/TEDICA,\n",
    "\n",
    "```{math}\n",
    ":label: te_independence_model4\n",
    "PE(TE_k) = {\\bar{S}(TE_k)} * X\n",
    "```\n",
    "\n",
    "Lastly, we fit X to the data and evaluate model fit.\n",
    "\n",
    "## TE-dependence model\n",
    "\n",
    "```{math}\n",
    ":label: te_dependence_model1\n",
    "\\frac{{\\Delta}S(TE_k)}{\\bar{S}(TE_k)} = -{\\Delta}{R_2^*}*TE_k\n",
    "```\n",
    "\n",
    "```{math}\n",
    ":label: te_dependence_model2\n",
    "{\\Delta}S(TE_k) = {\\bar{S}(TE_k)} * -{\\Delta}{R_2^*}*TE_k\n",
    "```\n",
    "\n",
    "$-{\\Delta}{R_2^*}$ is a scalar, so we ignore it,\n",
    "which means we only use ${\\bar{S}(TE_k)}$ (mean echo-wise-signal) and $TE_k$ (echo time in milliseconds).\n",
    "\n",
    "Thus,\n",
    "\n",
    "```{math}\n",
    ":label: te_dependence_model3\n",
    "{\\Delta}S(TE_k) = {\\bar{S}(TE_k)}*TE_k * X\n",
    "```\n",
    "\n",
    "and for TEDPCA/TEDICA,\n",
    "\n",
    "```{math}\n",
    ":label: te_dependence_model4\n",
    "PE(TE_k) = {\\bar{S}(TE_k)}*TE_k * X\n",
    "```\n",
    "\n",
    "Lastly, we fit X to the data and evaluate model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef6690",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "X1 = (mean_sig)[:, None]  # Model 1\n",
    "\n",
    "# NOTE: T2* is unnecessary for this, since it's a scalar\n",
    "X2 = ((echo_times * mean_sig) / mean_t2s)[:, None]  # Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676ba11",
   "metadata": {},
   "source": [
    "## Fitted curves for S0-perturbed signal\n",
    "\n",
    "The predicted curve for the S0 model matches the real curve perfectly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b6c10",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "B = d_sig2[:, None]  # (E x S)\n",
    "alpha = (np.abs(B) ** 2).sum(axis=0)\n",
    "\n",
    "# S0 Model\n",
    "coeffs_S0 = (B * X1).sum(axis=0) / (X1 ** 2).sum(axis=0)\n",
    "pred_S0 = X1 * np.tile(coeffs_S0, (n_echoes, 1))\n",
    "SSE_S0 = (B - pred_S0) ** 2\n",
    "SSE_S0 = SSE_S0.sum(axis=0)  # (S,) prediction error map\n",
    "F_S0 = (alpha - SSE_S0) * (n_echoes - 1) / (SSE_S0)\n",
    "pred_S0_2 = pred_S0.copy()\n",
    "\n",
    "# R2 Model\n",
    "coeffs_R2 = (B * X2).sum(axis=0) / (X2 ** 2).sum(axis=0)\n",
    "pred_R2 = X2 * np.tile(coeffs_R2, (n_echoes, 1))\n",
    "SSE_R2 = (B - pred_R2) ** 2\n",
    "SSE_R2 = SSE_R2.sum(axis=0)\n",
    "F_R2 = (alpha - SSE_R2) * (n_echoes - 1) / (SSE_R2)\n",
    "pred_R2_2 = pred_R2.copy()\n",
    "\n",
    "print(\"Rho: {}\".format(F_S0[0]))\n",
    "print(\"Kappa: {}\".format(F_R2[0]))\n",
    "print()\n",
    "\n",
    "# Parameter estimate * mean S0 gives delta(S0)\n",
    "print(\"Real delta S0: {}\".format(s02 - mean_s0))\n",
    "print(\"Delta S0 from results: {}\".format(coeffs_S0[0] * mean_s0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d0120",
   "metadata": {},
   "source": [
    "## Fitted curves for R2*-perturbed signal\n",
    "\n",
    "For some reason, the predicted curve for the R2 model doesn't match the real signal curve.\n",
    "What's with this mismatch?\n",
    "\n",
    "It seems like the mismatch increases as the difference between the fluctuating volume's R2 and the mean R2 increase.\n",
    "The fitted curve seems to actually match the mean signal, not the perturbed signal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325bdbea",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "B = d_sig3[:, None]  # (E x S)\n",
    "alpha = (np.abs(B) ** 2).sum(axis=0)\n",
    "\n",
    "# S0 Model\n",
    "coeffs_S0 = (B * X1).sum(axis=0) / (X1 ** 2).sum(axis=0)\n",
    "pred_S0 = X1 * np.tile(coeffs_S0, (n_echoes, 1))\n",
    "SSE_S0 = (B - pred_S0) ** 2\n",
    "SSE_S0 = SSE_S0.sum(axis=0)  # (S,) prediction error map\n",
    "F_S0 = (alpha - SSE_S0) * (n_echoes - 1) / (SSE_S0)\n",
    "pred_S0_3 = pred_S0.copy()\n",
    "\n",
    "# R2 Model\n",
    "coeffs_R2 = (B * X2).sum(axis=0) / (X2 ** 2).sum(axis=0)\n",
    "pred_R2 = X2 * np.tile(coeffs_R2, (n_echoes, 1))\n",
    "SSE_R2 = (B - pred_R2) ** 2\n",
    "SSE_R2 = SSE_R2.sum(axis=0)\n",
    "F_R2 = (alpha - SSE_R2) * (n_echoes - 1) / (SSE_R2)\n",
    "pred_R2_3 = pred_R2.copy()\n",
    "\n",
    "print(\"Rho: {}\".format(F_S0[0]))\n",
    "print(\"Kappa: {}\".format(F_R2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa1e3e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 2.5))\n",
    "\n",
    "axes[0].set_title(\"Change in S0\", fontsize=20, y=1.02)\n",
    "axes[0].plot(echo_times, d_sig2, label=\"${\\\\Delta}S(TE_k)$\", linewidth=5, alpha=0.5)\n",
    "axes[0].plot(\n",
    "    echo_times,\n",
    "    np.squeeze(pred_R2_2),\n",
    "    label=\"Predicted signal for R2* model\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    echo_times,\n",
    "    np.squeeze(pred_S0_2),\n",
    "    label=\"Predicted signal for S0 model\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"black\",\n",
    ")\n",
    "axes[0].set_xlim(0, np.max(echo_times))\n",
    "legend = axes[0].legend()\n",
    "\n",
    "axes[1].set_title(\"Change in T2*\", fontsize=20, y=1.02)\n",
    "axes[1].plot(echo_times, d_sig3, label=\"${\\\\Delta}S(TE_k)$\", linewidth=5, alpha=0.5)\n",
    "axes[1].plot(\n",
    "    echo_times,\n",
    "    np.squeeze(pred_R2_3),\n",
    "    label=\"Predicted signal for R2* model\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    ")\n",
    "axes[1].plot(\n",
    "    echo_times,\n",
    "    np.squeeze(pred_S0_3),\n",
    "    label=\"Predicted signal for S0 model\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"black\",\n",
    ")\n",
    "axes[1].set_xlim(0, np.max(echo_times))\n",
    "legend = axes[1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "glue(\"fig_fitted_r2_curves\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635fc674",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_fitted_r2_curves\n",
    ":name: fig_fitted_r2_curves\n",
    ":align: center\n",
    "\n",
    "Fitted curves for R2*-perturbed signal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5760aed2",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# lstsq gives same result as model fit method by kundu, which is great to see\n",
    "x, res, rank, sing = np.linalg.lstsq(X2, B, rcond=None)\n",
    "print(x[0])\n",
    "print(coeffs_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b19618",
   "metadata": {},
   "source": [
    "## Now let's apply this approach to components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823910d",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "# We'll convolve with HRF just for smoothness\n",
    "hrf = first_level.spm_hrf(1, oversampling=1)\n",
    "\n",
    "n_trs = 300\n",
    "\n",
    "frac = 0.05  # 5% PSC\n",
    "mean_t2s = 30\n",
    "t2s_std = mean_t2s * frac\n",
    "mean_s0 = 16000\n",
    "s0_std = mean_s0 * frac\n",
    "\n",
    "# simulate the T2*/S0 time series\n",
    "t2s_ts = np.random.normal(loc=mean_t2s, scale=t2s_std, size=(n_trs + 20,))\n",
    "t2s_ts = signal.convolve(t2s_ts, hrf)[20 : n_trs + 20]\n",
    "t2s_ts *= t2s_std / np.std(t2s_ts)\n",
    "t2s_ts += mean_t2s - np.mean(t2s_ts)\n",
    "\n",
    "s0_ts = np.random.normal(loc=mean_s0, scale=s0_std, size=(n_trs + 20,))\n",
    "s0_ts = signal.convolve(s0_ts, hrf)[20 : n_trs + 20]\n",
    "s0_ts *= s0_std / np.std(s0_ts)\n",
    "s0_ts += mean_s0 - np.mean(s0_ts)\n",
    "\n",
    "# Constant T2*/S0 time series\n",
    "mean_s0_ts = np.ones(n_trs) * mean_s0\n",
    "mean_t2s_ts = np.ones(n_trs) * mean_t2s\n",
    "\n",
    "# Simulate signal for each echo time\n",
    "t2s_signal = predict_bold_signal(echo_times, mean_s0_ts, t2s_ts)\n",
    "s0_signal = predict_bold_signal(echo_times, s0_ts, mean_t2s_ts)\n",
    "multiecho_signal = predict_bold_signal(echo_times, s0_ts, t2s_ts)\n",
    "\n",
    "# Normalize to get component time series\n",
    "t2s_ts_z = stats.zscore(t2s_ts)\n",
    "s0_ts_z = stats.zscore(s0_ts)\n",
    "p = 0.5  # proportion for combination\n",
    "component = (p * t2s_ts_z) + ((1 - p) * s0_ts_z)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "ax.plot(t2s_ts_z, label=\"T2* fluctuations\", color=\"blue\")\n",
    "ax.plot(s0_ts_z, label=\"S0 fluctuations\", color=\"red\")\n",
    "ax.plot(component, label=\"Component\", color=\"black\", alpha=0.5, linewidth=5)\n",
    "ax.set_xlim(0, n_trs - 1)\n",
    "ax.set_xlabel(\"Time (TR)\")\n",
    "leg = ax.legend(fontsize=14, ncol=3)\n",
    "glue(\"fig_component_curves\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272ed81",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_component_curves\n",
    ":name: fig_component_curves\n",
    ":align: center\n",
    "\n",
    "Now let's apply this approach to components\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d4f44",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "interval = int(np.floor(n_echoes / 7))\n",
    "echoes_to_plot = list(range(5, n_echoes, interval))\n",
    "fig, axes = plt.subplots(\n",
    "    len(echoes_to_plot), sharex=True, sharey=False, figsize=(14, 6)\n",
    ")\n",
    "\n",
    "for i_echo, echo in enumerate(echoes_to_plot):\n",
    "    axes[i_echo].plot(multiecho_signal[echo, :], color=pal[i_echo])\n",
    "    axes[i_echo].set_ylabel(\n",
    "        \"{0}ms\".format(echo_times[echo]),\n",
    "        rotation=0,\n",
    "        va=\"center\",\n",
    "        ha=\"right\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    axes[i_echo].set_yticks([])\n",
    "    axes[i_echo].set_xticks([])\n",
    "\n",
    "axes[-1].set_xlabel(\"Time\", fontsize=16)\n",
    "axes[-1].set_xlim(0, n_trs - 1)\n",
    "glue(\"fig_component_curves_2\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d8076",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_component_curves_2\n",
    ":name: fig_component_curves_2\n",
    ":align: center\n",
    "\n",
    "Now let's apply this approach to components again.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa8e8e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "interval = int(np.floor(n_echoes / 7))\n",
    "echoes_to_plot = list(range(5, n_echoes, interval))\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "for i_echo, echo in enumerate(echoes_to_plot):\n",
    "    rep_echo_times = np.ones(n_trs) * echo\n",
    "    ax.scatter(rep_echo_times, multiecho_signal[echo, :], alpha=0.05, color=pal[i_echo])\n",
    "\n",
    "max_signal = np.max(multiecho_signal, axis=1)\n",
    "min_signal = np.min(multiecho_signal, axis=1)\n",
    "ax.fill_between(echo_times, max_signal, min_signal, alpha=0.2)\n",
    "\n",
    "ax.set_ylabel(\"BOLD signal\", fontsize=16)\n",
    "ax.set_xlabel(\"Echo Time (ms)\", fontsize=16)\n",
    "ax.set_xticks(echoes_to_plot)\n",
    "ax.set_xlim(0, np.max(echo_times))\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "fig.tight_layout()\n",
    "glue(\"fig_component_curves_3\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae303c",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_component_curves_3\n",
    ":name: fig_component_curves_3\n",
    ":align: center\n",
    "\n",
    "Now let's apply this approach to components again.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b77ac",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "\n",
    "# Add a constant term to the array\n",
    "comp_X = np.hstack((component[:, None], np.ones((component.shape[0], 1))))\n",
    "pes, _, _, _ = np.linalg.lstsq(comp_X, multiecho_signal.T, rcond=None)\n",
    "pes = pes[0, :]\n",
    "\n",
    "F_S0, F_R2, pred_S0, pred_R2 = compute_te_dependence_statistics(\n",
    "    multiecho_signal, pes, echo_times\n",
    ")\n",
    "ax.plot(echo_times, pred_R2, label=\"Predicted T2* model values\", c=\"blue\")\n",
    "ax.plot(echo_times, pred_S0, label=\"Predicted S0 model values\", c=\"red\")\n",
    "ax.plot(echo_times, pes, label=\"Component PEs\", alpha=0.5, linewidth=5, c=\"black\")\n",
    "ax.plot(echo_times, pred_R2, label=r\"$\\kappa$ = {:.02f}\".format(F_R2[0]), alpha=0)\n",
    "ax.plot(echo_times, pred_S0, label=r\"$\\rho$ = {:.02f}\".format(F_S0[0]), alpha=0)\n",
    "ax.set_xlim(0, np.max(echo_times))\n",
    "ax.set_xlabel(\"Echo time (ms)\")\n",
    "leg = ax.legend(fontsize=14, ncol=2)\n",
    "glue(\"fig_component_curves_4\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c981c",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_component_curves_4\n",
    ":name: fig_component_curves_4\n",
    ":align: center\n",
    "\n",
    "Now let's apply this approach to components again.\n",
    "```\n",
    "\n",
    "```{prf:algorithm} Minimum image regression\n",
    ":label: minimum-image-regression\n",
    "<!-- Written by Taylor Salo, Jessica Bartley, and Elizabeth DuPre -->\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "- $\\mathbf{O}$ is the matrix of optimally combined (OC) data, of shape $v \\times t$,\n",
    "where $v$ is the number of voxels in the brain mask and $t$ is the number of timepoints in the scan.\n",
    "- $\\mathbf{M}$ is the mixing matrix from the ICA decomposition, of shape $c \\times t$, where $c$ is the number of components.\n",
    "- $W$ is the set of indices of all components in $\\mathbf{M}$: $W = \\{1, 2, 3, ..., c\\}$\n",
    "- $N$ is the set of indices of all non-ignored components (i.e., all accepted or BOLD-like, and rejected or non-BOLD components) in\n",
    "  $\\mathbf{M}$: $N \\in \\mathbb{N}^k \\text{ s.t } 1 \\leq k \\leq c, N \\subseteq W$\n",
    "- $A$ is the set of indices of all accepted (i.e., BOLD-like) components in $\\mathbf{M}$:\n",
    "  $A \\in \\mathbb{N}^l \\text{ s.t } 1 \\leq l \\leq k, A \\subseteq N$\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "- Multi-echo denoised data without the T1-like effect, referred to as $\\mathbf{D}$ or MEDN+MIR.\n",
    "- Multi-echo BOLD-like data without the T1-like effect, referred to as $\\mathbf{H}$ or MEHK+MIR.\n",
    "- ICA mixing matrix with the T1-like effect removed from component time series ($\\mathbf{K}$).\n",
    "- Map of the T1-like effect ($\\mathbf{m}$)\n",
    "\n",
    "**Algorithm**\n",
    "\n",
    "1.  The voxel-wise means ($\\mathbf{\\overline{O}} \\in \\mathbb{R}^{v}$) and standard deviations\n",
    "    ($\\mathbf{\\sigma_{O}} \\in \\mathbb{R}^{v}$) of the optimally combined data are computed over time.\n",
    "2.  The optimally combined data are z-normalized over time ($\\mathbf{O_z} \\in \\mathbb{R}^{v \\times t}$).\n",
    "3.  The normalized optimally combined data matrix ($\\mathbf{O_z}$) is regressed on the ICA mixing matrix\n",
    "    ($\\mathbf{M} \\in \\mathbb{R}^{c \\times t}$) to construct component-wise parameter estimate maps\n",
    "    ($\\mathbf{B} \\in \\mathbb{R}^{v \\times c}$).\n",
    "\n",
    "    <!-- no intercept included, because unnecessary and data are normalized. -->\n",
    "    $$\n",
    "        \\mathbf{O_{z}} = \\mathbf{B} \\mathbf{M} + \\mathbf{\\epsilon}, \\enspace \\mathbf{\\epsilon} \\in \\mathbb{R}^{v \\times t}\n",
    "    $$\n",
    "\n",
    "4.  $N$ is used to select rows from the mixing matrix $\\mathbf{M}$ and columns from the parameter estimate matrix $\\mathbf{B}$\n",
    "    that correspond to non-ignored (i.e., accepted and rejected) components, forming reduced matrices $\\mathbf{M}_N$ and $\\mathbf{B}_N$.\n",
    "    The normalized time series matrix for the combined ignored components and variance left unexplained by the ICA decomposition is then\n",
    "    computed by subtracting the scalar product of the non-ignored beta weight and mixing matrices from the normalized OC data time series\n",
    "    ($\\mathbf{O_{z}}$).\n",
    "    The result is referred to as the normalized residuals time series matrix ($\\mathbf{R} \\in \\mathbb{R}^{v \\times t}$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{R} = \\mathbf{O_{z}} - \\mathbf{B}_N \\mathbf{M}_N, \\enspace \\mathbf{B}_N \\in \\mathbb{R}^{v \\times |N|},\n",
    "        \\enspace \\mathbf{M}_N \\in \\mathbb{R}^{|N| \\times t}\n",
    "    $$\n",
    "\n",
    "5.  We can likewise construct the normalized time series of BOLD-like components ($\\mathbf{P} \\in \\mathbb{R}^{v \\times t}$) by\n",
    "    multiplying similarly reduced parameter estimate and mixing matrices composed of only the columns and rows, respectively,\n",
    "    that are associated with the accepted components indexed in $A$.\n",
    "    The resulting time series matrix is similar to the time series matrix referred to elsewhere in the manuscript as\n",
    "    multi-echo high-Kappa (MEHK), with the exception that the component time series have been normalized prior to reconstruction.\n",
    "\n",
    "    $$\n",
    "        \\mathbf{P} = \\mathbf{B}_A \\mathbf{M}_A, \\enspace \\mathbf{B}_A \\in \\mathbb{R}^{v \\times |A|},\n",
    "        \\enspace \\mathbf{M}_A \\in \\mathbb{R}^{|A| \\times t}\n",
    "    $$\n",
    "\n",
    "6.  The map of the T1-like effect ($\\mathbf{m} \\in \\mathbb{R}^{v}$) is constructed by taking the minimum across timepoints\n",
    "    from the normalized MEHK time series ($\\mathbf{P}$) and then mean-centering across brain voxels.\n",
    "    Let $J = \\{1, ..., t\\}$ denote the indices of the columns of matrix $\\mathbf{P}$, and let $p_{ij}$ denote the value of the\n",
    "    element $\\mathbf{P}[i,j]$.\n",
    "\n",
    "    <!-- adapted from https://math.stackexchange.com/a/871689 -->\n",
    "    $$\n",
    "        \\mathbf{q_{i}} = \\min_{j\\in{J}}p_{ij} \\quad \\forall  i = 1,...,v\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "        \\mathbf{m} = \\mathbf{q} - \\mathbf{\\overline{q}}, \\enspace \\mathbf{q} \\in \\mathbb{R}^{v}\n",
    "    $$\n",
    "\n",
    "7.  The standardized optimally combined time series matrix ($\\mathbf{O_z}$) is regressed on the T1-like effect map\n",
    "    ($\\mathbf{m}$) to estimate the volume-wise global signal time series ($\\mathbf{g} \\in \\mathbb{R}^t$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{O_{z}} = \\mathbf{m} \\otimes \\mathbf{g} + \\mathbf{\\epsilon}, \\enspace \\mathbf{\\epsilon} \\in \\mathbb{R}^{v \\times t}\n",
    "    $$\n",
    "\n",
    "    Where $\\otimes$ is the outer product.\n",
    "\n",
    "8.  The normalized BOLD time series matrix ($\\mathbf{P}$) is then regressed on this global signal time series ($\\mathbf{g}$)\n",
    "    in order to estimate a global signal map ($\\mathbf{s} \\in \\mathbb{R}^v$) and the normalized BOLD time series matrix without\n",
    "    the T1-like effect ($\\mathbf{E} \\in \\mathbb{R}^{v \\times t}$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{P} = \\mathbf{g} \\otimes \\mathbf{s} + \\mathbf{E}\n",
    "    $$\n",
    "\n",
    "9.  The time series matrix of BOLD-like components without the T1-like effect (MEHK+MIR, $\\mathbf{H} \\in \\mathbb{R}^{v \\times t}$),\n",
    "    scaled to match the original OC time series matrix, is constructed by multiplying each column of $\\mathbf{E}$ by the vector\n",
    "    $\\mathbf{\\sigma_{O}}$.\n",
    "\n",
    "    $$\n",
    "        \\mathbf{H} = \\mathbf{E} \\circ\n",
    "        \\underbrace{\n",
    "            \\pmatrix{\n",
    "                \\mathbf{{\\sigma_{O}}_1} & \\cdots & \\mathbf{{\\sigma_{O}}_1}\\\\\n",
    "                \\vdots & \\vdots & \\vdots \\\\\n",
    "                \\mathbf{{\\sigma_{O}}_v} & \\cdots & \\mathbf{{\\sigma_{O}}_v}\\\\\n",
    "            }\n",
    "        }_{t}\n",
    "    $$\n",
    "\n",
    "    Where $\\circ$ is the [Hadamard product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices))\n",
    "    for element-wise multiplication of two matrices.\n",
    "\n",
    "10. The ICA-denoised time series without the T1-like effect (MEDN+MIR, $\\mathbf{D} \\in \\mathbb{R}^{v \\times t}$)\n",
    "    is constructed by adding the residuals time series ($\\mathbf{R}$) to the normalized BOLD time series ($\\mathbf{E}$),\n",
    "    multiplying each column of the result by the vector $\\sigma_{O}$, and adding back in the voxel-wise mean of the OC time series\n",
    "    ($\\mathbf{\\overline{O}}$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{D} = \\mathbf{\\overline{O}} + (\\mathbf{E} + \\mathbf{R}) \\circ\n",
    "        \\underbrace{\n",
    "            \\pmatrix{\n",
    "                \\mathbf{{\\sigma_{O}}_1} & \\cdots & \\mathbf{{\\sigma_{O}}_1}\\\\\n",
    "                \\vdots & \\vdots & \\vdots \\\\\n",
    "                \\mathbf{{\\sigma_{O}}_v} & \\cdots & \\mathbf{{\\sigma_{O}}_v}\\\\\n",
    "            }\n",
    "        }_{t}\n",
    "    $$\n",
    "\n",
    "11. The T1c-corrected ICA mixing matrix is then derived by regressing the global signal time series $\\mathbf{g}$ from\n",
    "    each component's time series. Let $\\mathbf{Q}$ be the associated parameter estimate matrix\n",
    "    ($\\mathbf{Q} \\in \\mathbb{R}^{c \\times t}$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{M} = \\mathbf{Q}\\mathbf{g} + \\mathbf{K}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "        \\mathbf{K} = \\mathbf{M} - \\mathbf{Q}\\mathbf{g}\n",
    "    $$\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "source_map": [
   12,
   49,
   76,
   103,
   107,
   196,
   273,
   279,
   285,
   313,
   323,
   348,
   392,
   401,
   407,
   411,
   459,
   468,
   491,
   500,
   520,
   529,
   550
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}