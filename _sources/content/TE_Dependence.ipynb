{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29a2858",
   "metadata": {},
   "source": [
    "# BOLD, non-BOLD, and TE-dependence with tedana\n",
    "\n",
    "```{important}\n",
    "This chapter should differentiate itself from Signal_Decay by focusing on the application of {eq}`monoexponential_decay`\n",
    "to decompositions, rather than raw signal compared between active and inactive states.\n",
    "\n",
    "We may want to describe adaptive masking, data whitening, the model fit metrics, and post-processing methods (e.g., MIR)\n",
    "in this page as well.\n",
    "```\n",
    "\n",
    "```{important}\n",
    "The general flow of this chapter should be:\n",
    "\n",
    "1.  Explain the monoexponential decay equation, but primarily reference back to Signal_Decay.\n",
    "2.  Walk through optimal combination and adaptive masking somewhere around here.\n",
    "3.  Describe why multi-echo denoising can't be done directly to the raw signal and why ICA is necessary.\n",
    "    1.  This mean talking about noise, really, and why the FIT method (volume-wise T2*/S0 estimation)\n",
    "        is generally considered too noisy for practical application.\n",
    "    2.  Walk through TEDPCA as well.\n",
    "4.  The TE-(in)dependence models.\n",
    "5.  Apply the models to a simulated component, as well as multiple real components.\n",
    "    1.  Show model fit for different components.\n",
    "6.  Compare optimally combined, denoised, and high-kappa data.\n",
    "7.  Describe post-processing methods, like minimum image regression and tedana's version of global signal regression.\n",
    "```\n",
    "\n",
    "This notebook uses simulated T2*/S0 manipulations to show how TE-dependence is leveraged to denoise multi-echo data.\n",
    "\n",
    "The equation for how signal is dependent on changes in S0 and T2*:\n",
    "\n",
    "```{math}\n",
    ":label: monoexponential_decay\n",
    "S(t, TE_k) = \\bar{S}(TE_k) * (1 + \\frac{{\\Delta}{S_0}(t)}{\\bar{S}_0} - {\\Delta}{R_2^*}(t)*TE_k)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef242f2",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- repo2data starting ----\n",
      "/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/repo2data\n",
      "Config from file :\n",
      "../binder/data_requirement.json\n",
      "Destination:\n",
      "./../data/ds006193/multi-echo-data-analysis\n",
      "\n",
      "Info : Starting to download from datalad https://github.com/OpenNeuroDatasets/ds006193.git ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is highly recommended to configure Git before using DataLad. Set both 'user.name' and 'user.email' configuration variables.\n",
      "[INFO] Attempting a clone into /home/runner/work/multi-echo-data-analysis/multi-echo-data-analysis/data/ds006193/multi-echo-data-analysis \n",
      "[INFO] Attempting to clone from https://github.com/OpenNeuroDatasets/ds006193.git to /home/runner/work/multi-echo-data-analysis/multi-echo-data-analysis/data/ds006193/multi-echo-data-analysis \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start enumerating objects \n",
      "[INFO] Start counting objects \n",
      "[INFO] Start compressing objects \n",
      "[INFO] Start receiving objects \n",
      "[INFO] Start resolving deltas \n",
      "[INFO] Completed clone attempts for Dataset(/home/runner/work/multi-echo-data-analysis/multi-echo-data-analysis/data/ds006193/multi-echo-data-analysis) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "install(error): /home/runner/work/multi-echo-data-analysis/multi-echo-data-analysis/data/ds006193/multi-echo-data-analysis (dataset) [No working git-annex installation of version >= 8.20200309. Visit http://handbook.datalad.org/r.html?install for instructions on how to install DataLad and git-annex.] [No working git-annex installation of version >= 8.20200309. Visit http://handbook.datalad.org/r.html?install for instructions on how to install DataLad and git-annex.]\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['datalad', 'install', './../data/ds006193/multi-echo-data-analysis', '-s', 'https://github.com/OpenNeuroDatasets/ds006193.git']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Download data\u001b[39;00m\n\u001b[1;32m     18\u001b[0m repo2data \u001b[38;5;241m=\u001b[39m Repo2Data(DATA_REQ_FILE)\n\u001b[0;32m---> 19\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[43mrepo2data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(data_path[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     22\u001b[0m out_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte-dependence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/repo2data/repo2data.py:106\u001b[0m, in \u001b[0;36mRepo2Data.install\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_requirement_file\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    105\u001b[0m             ret \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mRepo2DataChild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 106\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_requirement_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server_dst_folder\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# if not, it is a single assignment\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     ret \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [Repo2DataChild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_requirement_file,\n\u001b[1;32m    110\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_server, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_requirement_path, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_dst_folder)\u001b[38;5;241m.\u001b[39minstall()]\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/repo2data/repo2data.py:364\u001b[0m, in \u001b[0;36mRepo2DataChild.install\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dst_path)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Downloading with the right method, depending on the src type\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scan_dl_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# If needed, decompression of the data\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_archive_decompress()\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/repo2data/repo2data.py:332\u001b[0m, in \u001b[0;36mRepo2DataChild._scan_dl_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# if the source link has a .git, we use datalad\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*?\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m.git$\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_requirement_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datalad_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# or coming from google drive\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*?(drive\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m.google\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m.com).*?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_requirement_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/repo2data/repo2data.py:263\u001b[0m, in \u001b[0;36mRepo2DataChild._datalad_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfo : Starting to download from datalad \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    261\u001b[0m       (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_requirement_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatalad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_requirement_file\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: datalad does not appear to be installed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/subprocess.py:369\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['datalad', 'install', './../data/ds006193/multi-echo-data-analysis', '-s', 'https://github.com/OpenNeuroDatasets/ds006193.git']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from book_utils import compute_te_dependence_statistics, predict_bold_signal\n",
    "from myst_nb import glue\n",
    "from nilearn.glm import first_level\n",
    "from repo2data.repo2data import Repo2Data\n",
    "from scipy import signal, stats\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Install the data if running locally, or point to cached data if running on neurolibre\n",
    "DATA_REQ_FILE = os.path.join(\"../binder/data_requirement.json\")\n",
    "\n",
    "# Download data\n",
    "repo2data = Repo2Data(DATA_REQ_FILE)\n",
    "data_path = repo2data.install()\n",
    "data_path = os.path.abspath(data_path[0])\n",
    "\n",
    "out_dir = os.path.join(data_path, \"te-dependence\")\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98332b",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "# For a nice, smooth curve\n",
    "echo_times = np.arange(0, 201, 1)\n",
    "\n",
    "n_echoes = len(echo_times)\n",
    "pal = sns.color_palette(\"cubehelix\", 8)\n",
    "\n",
    "mean_s0 = 16000\n",
    "mean_t2s = 30\n",
    "\n",
    "frac = 0.2\n",
    "s02 = mean_s0 + (mean_s0 * frac)\n",
    "t2s2 = mean_t2s + (mean_t2s * frac)\n",
    "\n",
    "mean_sig = np.squeeze(predict_bold_signal(echo_times, mean_s0, mean_t2s))\n",
    "\n",
    "# Signal with fluctuating S0\n",
    "sig2 = np.squeeze(predict_bold_signal(echo_times, s02, mean_t2s))\n",
    "d_sig2 = sig2 - mean_sig\n",
    "dt_sig2 = d_sig2 / ((sig2 + mean_sig) / 2.0)\n",
    "\n",
    "# Signal with fluctuating T2*\n",
    "sig3 = np.squeeze(predict_bold_signal(echo_times, mean_s0, t2s2))\n",
    "d_sig3 = sig3 - mean_sig\n",
    "dt_sig3 = d_sig3 / ((sig3 + mean_sig) / 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655fbb0",
   "metadata": {},
   "source": [
    "## Plot simulations of BOLD and non-BOLD signals as a function of echo time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee0167",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# change s0\n",
    "fig, axes = plt.subplots(3, 2, sharex=True, figsize=(16, 6))\n",
    "axes[0, 0].yaxis.tick_right()\n",
    "axes[0, 0].set_xticklabels([])\n",
    "axes[0, 0].plot(echo_times, mean_sig, \"red\", label=\"Mean signal\")\n",
    "axes[0, 0].plot(echo_times, sig2, \"blue\", label=\"Timepoint's signal\")\n",
    "axes[0, 0].set_ylim(0)\n",
    "axes[0, 0].set_title(\"Change in S0\", fontsize=20, y=1.02)\n",
    "axes[0, 0].set_ylabel(\n",
    "    \"Signal\\n$S(TE_n)$\", fontsize=16, rotation=0, labelpad=40, va=\"center\"\n",
    ")\n",
    "leg = axes[0, 0].legend()\n",
    "\n",
    "axes[1, 0].yaxis.tick_right()\n",
    "axes[1, 0].set_xticklabels([])\n",
    "axes[1, 0].plot(echo_times, d_sig2, \"red\")\n",
    "axes[1, 0].set_ylim(0)\n",
    "axes[1, 0].set_ylabel(\n",
    "    \"${\\\\Delta}S(TE_n)$\", fontsize=16, rotation=0, labelpad=40, va=\"center\"\n",
    ")\n",
    "\n",
    "# No slope, intercept at delta(S0)/mean(S0)\n",
    "axes[2, 0].yaxis.tick_right()\n",
    "axes[2, 0].plot(echo_times, dt_sig2, \"red\")\n",
    "axes[2, 0].set_ylabel(\n",
    "    \"$\\\\frac{{\\\\Delta}S(TE_n)}{\\\\bar{S}(TE_n)}$\",\n",
    "    fontsize=24,\n",
    "    rotation=0,\n",
    "    labelpad=40,\n",
    "    va=\"center\",\n",
    ")\n",
    "axes[2, 0].set_xlabel(\"Echo Time (ms)\", fontsize=16)\n",
    "\n",
    "# change t2s\n",
    "# max diff is between orig and new T2*, but is definitely not mean\n",
    "max_diff_te = echo_times[d_sig3 == np.max(d_sig3)][0]\n",
    "\n",
    "axes[0, 1].yaxis.tick_right()\n",
    "axes[0, 1].set_xticklabels([])\n",
    "axes[0, 1].plot(echo_times, mean_sig, \"red\", label=\"Mean signal\")\n",
    "axes[0, 1].plot(echo_times, sig3, \"blue\", label=\"Timepoint's signal\")\n",
    "axes[0, 1].set_ylim(0)\n",
    "axes[0, 1].set_title(\"Change in T2*\", fontsize=20, y=1.02)\n",
    "\n",
    "# Plot important echo times\n",
    "axes[0, 1].axvline(mean_t2s, color=\"green\", alpha=0.5)\n",
    "axes[0, 1].axvline(max_diff_te, color=\"gray\", alpha=0.5)\n",
    "axes[0, 1].axvline(t2s2, color=\"orange\", alpha=0.5)\n",
    "leg = axes[0, 1].legend()\n",
    "\n",
    "axes[1, 1].yaxis.tick_right()\n",
    "axes[1, 1].set_xticklabels([])\n",
    "axes[1, 1].plot(echo_times, d_sig3, \"red\")\n",
    "axes[1, 1].set_ylim(0)\n",
    "\n",
    "# Plot important echo times\n",
    "axes[1, 1].axvline(mean_t2s, label=\"T2* of mean data\", color=\"green\", alpha=0.5)\n",
    "axes[1, 1].axvline(\n",
    "    max_diff_te, label=\"TE of maximized contrast\", color=\"gray\", alpha=0.5\n",
    ")\n",
    "axes[1, 1].axvline(t2s2, label=\"T2* of timepoint's data\", color=\"orange\", alpha=0.5)\n",
    "leg = axes[1, 1].legend()\n",
    "\n",
    "pred_slope = (dt_sig3[-1] - dt_sig3[0]) / (echo_times[-1] - echo_times[0])\n",
    "pred_int = (pred_slope * echo_times[-1]) - dt_sig3[-1]\n",
    "pred_max = pred_slope * echo_times[-1]\n",
    "\n",
    "axes[2, 1].yaxis.tick_right()\n",
    "axes[2, 1].plot(echo_times, dt_sig3, \"red\")\n",
    "axes[2, 1].plot(\n",
    "    [0, echo_times[-1]],\n",
    "    [pred_int, pred_max],\n",
    "    \"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Theoretical line\",\n",
    ")\n",
    "axes[2, 1].set_ylim(0, None)\n",
    "axes[2, 1].set_xlim(0, np.max(echo_times))\n",
    "# axes[2, 1].set_xticks(echo_times)\n",
    "axes[2, 1].set_xlabel(\"Echo Time (ms)\", fontsize=16)\n",
    "axes[2, 1].axvline(max_diff_te, color=\"gray\", alpha=0.5)\n",
    "axes[2, 1].axvline(mean_t2s, color=\"green\", alpha=0.5)\n",
    "axes[2, 1].axvline(t2s2, color=\"orange\", alpha=0.5)\n",
    "leg = axes[2, 1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "glue(\"fig_bold_nonbold_simulations\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d561a31e",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_bold_nonbold_simulations\n",
    ":name: fig_bold_nonbold_simulations\n",
    ":align: center\n",
    "\n",
    "Simulations of BOLD and non-BOLD signals as a function of echo time\n",
    "```\n",
    "\n",
    "## Make design matrices\n",
    "\n",
    "For TEDPCA and TEDICA, we use regression to get parameter estimates (PEs; not beta values)\n",
    "for component time-series against echo-specific data, and substitute those PEs for ${\\bar{S}(TE_k)}$.\n",
    "At some point, I would like to dig into why those parameter estimates are equivalent to ${\\bar{S}(TE_k)}$ for our purposes.\n",
    "\n",
    "## TE-independence model\n",
    "\n",
    "```{math}\n",
    ":label: te_independence_model1\n",
    "\\frac{{\\Delta}S(TE_k)}{\\bar{S(TE_k)}} = \\frac{{\\Delta}S_0}{S_0}\n",
    "```\n",
    "\n",
    "```{math}\n",
    ":label: te_independence_model2\n",
    "{\\Delta}S(TE_k) = {\\bar{S}(TE_k)}\\frac{{\\Delta}S_0}{S_0}\n",
    "```\n",
    "\n",
    "$\\frac{{\\Delta}S_0}{S_0}$ is a scalar (i.e., doesn't change with TE), so we ignore that,\n",
    "which means we only use ${\\bar{S}(TE_k)}$ (mean echo-wise signal).\n",
    "\n",
    "Thus,\n",
    "\n",
    "```{math}\n",
    ":label: te_independence_model3\n",
    "{\\Delta}S(TE_k) = {\\bar{S}(TE_k)} * X\n",
    "```\n",
    "\n",
    "and for TEDPCA/TEDICA,\n",
    "\n",
    "```{math}\n",
    ":label: te_independence_model4\n",
    "PE(TE_k) = {\\bar{S}(TE_k)} * X\n",
    "```\n",
    "\n",
    "Lastly, we fit X to the data and evaluate model fit.\n",
    "\n",
    "## TE-dependence model\n",
    "\n",
    "```{math}\n",
    ":label: te_dependence_model1\n",
    "\\frac{{\\Delta}S(TE_k)}{\\bar{S}(TE_k)} = -{\\Delta}{R_2^*}*TE_k\n",
    "```\n",
    "\n",
    "```{math}\n",
    ":label: te_dependence_model2\n",
    "{\\Delta}S(TE_k) = {\\bar{S}(TE_k)} * -{\\Delta}{R_2^*}*TE_k\n",
    "```\n",
    "\n",
    "$-{\\Delta}{R_2^*}$ is a scalar, so we ignore it,\n",
    "which means we only use ${\\bar{S}(TE_k)}$ (mean echo-wise-signal) and $TE_k$ (echo time in milliseconds).\n",
    "\n",
    "Thus,\n",
    "\n",
    "```{math}\n",
    ":label: te_dependence_model3\n",
    "{\\Delta}S(TE_k) = {\\bar{S}(TE_k)}*TE_k * X\n",
    "```\n",
    "\n",
    "and for TEDPCA/TEDICA,\n",
    "\n",
    "```{math}\n",
    ":label: te_dependence_model4\n",
    "PE(TE_k) = {\\bar{S}(TE_k)}*TE_k * X\n",
    "```\n",
    "\n",
    "Lastly, we fit X to the data and evaluate model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71158429",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "X1 = (mean_sig)[:, None]  # Model 1\n",
    "\n",
    "# NOTE: T2* is unnecessary for this, since it's a scalar\n",
    "X2 = ((echo_times * mean_sig) / mean_t2s)[:, None]  # Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b9e8d8",
   "metadata": {},
   "source": [
    "## Fitted curves for S0-perturbed signal\n",
    "\n",
    "The predicted curve for the S0 model matches the real curve perfectly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed68d25",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "B = d_sig2[:, None]  # (E x S)\n",
    "alpha = (np.abs(B) ** 2).sum(axis=0)\n",
    "\n",
    "# S0 Model\n",
    "coeffs_S0 = (B * X1).sum(axis=0) / (X1 ** 2).sum(axis=0)\n",
    "pred_S0 = X1 * np.tile(coeffs_S0, (n_echoes, 1))\n",
    "SSE_S0 = (B - pred_S0) ** 2\n",
    "SSE_S0 = SSE_S0.sum(axis=0)  # (S,) prediction error map\n",
    "F_S0 = (alpha - SSE_S0) * (n_echoes - 1) / (SSE_S0)\n",
    "pred_S0_2 = pred_S0.copy()\n",
    "\n",
    "# R2 Model\n",
    "coeffs_R2 = (B * X2).sum(axis=0) / (X2 ** 2).sum(axis=0)\n",
    "pred_R2 = X2 * np.tile(coeffs_R2, (n_echoes, 1))\n",
    "SSE_R2 = (B - pred_R2) ** 2\n",
    "SSE_R2 = SSE_R2.sum(axis=0)\n",
    "F_R2 = (alpha - SSE_R2) * (n_echoes - 1) / (SSE_R2)\n",
    "pred_R2_2 = pred_R2.copy()\n",
    "\n",
    "print(\"Rho: {}\".format(F_S0[0]))\n",
    "print(\"Kappa: {}\".format(F_R2[0]))\n",
    "print()\n",
    "\n",
    "# Parameter estimate * mean S0 gives delta(S0)\n",
    "print(\"Real delta S0: {}\".format(s02 - mean_s0))\n",
    "print(\"Delta S0 from results: {}\".format(coeffs_S0[0] * mean_s0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f1487",
   "metadata": {},
   "source": [
    "## Fitted curves for R2*-perturbed signal\n",
    "\n",
    "For some reason, the predicted curve for the R2 model doesn't match the real signal curve.\n",
    "What's with this mismatch?\n",
    "\n",
    "It seems like the mismatch increases as the difference between the fluctuating volume's R2 and the mean R2 increase.\n",
    "The fitted curve seems to actually match the mean signal, not the perturbed signal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749ca55",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "B = d_sig3[:, None]  # (E x S)\n",
    "alpha = (np.abs(B) ** 2).sum(axis=0)\n",
    "\n",
    "# S0 Model\n",
    "coeffs_S0 = (B * X1).sum(axis=0) / (X1 ** 2).sum(axis=0)\n",
    "pred_S0 = X1 * np.tile(coeffs_S0, (n_echoes, 1))\n",
    "SSE_S0 = (B - pred_S0) ** 2\n",
    "SSE_S0 = SSE_S0.sum(axis=0)  # (S,) prediction error map\n",
    "F_S0 = (alpha - SSE_S0) * (n_echoes - 1) / (SSE_S0)\n",
    "pred_S0_3 = pred_S0.copy()\n",
    "\n",
    "# R2 Model\n",
    "coeffs_R2 = (B * X2).sum(axis=0) / (X2 ** 2).sum(axis=0)\n",
    "pred_R2 = X2 * np.tile(coeffs_R2, (n_echoes, 1))\n",
    "SSE_R2 = (B - pred_R2) ** 2\n",
    "SSE_R2 = SSE_R2.sum(axis=0)\n",
    "F_R2 = (alpha - SSE_R2) * (n_echoes - 1) / (SSE_R2)\n",
    "pred_R2_3 = pred_R2.copy()\n",
    "\n",
    "print(\"Rho: {}\".format(F_S0[0]))\n",
    "print(\"Kappa: {}\".format(F_R2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e5be9",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 2.5))\n",
    "\n",
    "axes[0].set_title(\"Change in S0\", fontsize=20, y=1.02)\n",
    "axes[0].plot(echo_times, d_sig2, label=\"${\\\\Delta}S(TE_k)$\", linewidth=5, alpha=0.5)\n",
    "axes[0].plot(\n",
    "    echo_times,\n",
    "    np.squeeze(pred_R2_2),\n",
    "    label=\"Predicted signal for R2* model\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    echo_times,\n",
    "    np.squeeze(pred_S0_2),\n",
    "    label=\"Predicted signal for S0 model\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"black\",\n",
    ")\n",
    "axes[0].set_xlim(0, np.max(echo_times))\n",
    "legend = axes[0].legend()\n",
    "\n",
    "axes[1].set_title(\"Change in T2*\", fontsize=20, y=1.02)\n",
    "axes[1].plot(echo_times, d_sig3, label=\"${\\\\Delta}S(TE_k)$\", linewidth=5, alpha=0.5)\n",
    "axes[1].plot(\n",
    "    echo_times,\n",
    "    np.squeeze(pred_R2_3),\n",
    "    label=\"Predicted signal for R2* model\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"red\",\n",
    ")\n",
    "axes[1].plot(\n",
    "    echo_times,\n",
    "    np.squeeze(pred_S0_3),\n",
    "    label=\"Predicted signal for S0 model\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"black\",\n",
    ")\n",
    "axes[1].set_xlim(0, np.max(echo_times))\n",
    "legend = axes[1].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "glue(\"fig_fitted_r2_curves\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a6ef1",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_fitted_r2_curves\n",
    ":name: fig_fitted_r2_curves\n",
    ":align: center\n",
    "\n",
    "Fitted curves for R2*-perturbed signal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9f67e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# lstsq gives same result as model fit method by kundu, which is great to see\n",
    "x, res, rank, sing = np.linalg.lstsq(X2, B, rcond=None)\n",
    "print(x[0])\n",
    "print(coeffs_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023836d",
   "metadata": {},
   "source": [
    "## Now let's apply this approach to components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8c97b",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "# We'll convolve with HRF just for smoothness\n",
    "hrf = first_level.spm_hrf(1, oversampling=1)\n",
    "\n",
    "n_trs = 300\n",
    "\n",
    "frac = 0.05  # 5% PSC\n",
    "mean_t2s = 30\n",
    "t2s_std = mean_t2s * frac\n",
    "mean_s0 = 16000\n",
    "s0_std = mean_s0 * frac\n",
    "\n",
    "# simulate the T2*/S0 time series\n",
    "n_chunks = 10\n",
    "scales = np.random.random(n_chunks) * 3\n",
    "t2s_ts = []\n",
    "for section in range(n_chunks):\n",
    "    ts = np.hstack((np.zeros(10), np.ones(20), np.zeros(10)))\n",
    "    ts *= scales[section]\n",
    "    t2s_ts.append(ts)\n",
    "\n",
    "t2s_ts = np.hstack(t2s_ts)[:n_trs + 20]\n",
    "t2s_ts = signal.convolve(t2s_ts, hrf)[:n_trs]\n",
    "t2s_ts *= t2s_std / np.std(t2s_ts)\n",
    "t2s_ts += mean_t2s - np.mean(t2s_ts)\n",
    "\n",
    "s0_ts = np.random.randint(0, 2, n_trs).astype(float)\n",
    "s0_ts -= 0.5\n",
    "s0_ts *= np.random.normal(loc=1, scale=0.25, size=n_trs)\n",
    "s0_ts = np.sort(s0_ts)\n",
    "first_half = s0_ts[:n_trs // 2]\n",
    "second_half = s0_ts[n_trs // 2:]\n",
    "s0_ts = np.zeros(n_trs)\n",
    "np.random.shuffle(first_half)\n",
    "np.random.shuffle(second_half)\n",
    "s0_ts[::2] = first_half\n",
    "s0_ts[1::2] = second_half\n",
    "# s0_ts = signal.convolve(s0_ts, hrf)[20 : n_trs + 20]\n",
    "s0_ts *= s0_std / np.std(s0_ts)\n",
    "s0_ts += mean_s0 - np.mean(s0_ts)\n",
    "\n",
    "# Constant T2*/S0 time series\n",
    "mean_s0_ts = np.ones(n_trs) * mean_s0\n",
    "mean_t2s_ts = np.ones(n_trs) * mean_t2s\n",
    "\n",
    "# Simulate signal for each echo time\n",
    "t2s_signal = predict_bold_signal(echo_times, mean_s0_ts, t2s_ts)\n",
    "s0_signal = predict_bold_signal(echo_times, s0_ts, mean_t2s_ts)\n",
    "multiecho_signal = predict_bold_signal(echo_times, s0_ts, t2s_ts)\n",
    "\n",
    "# Normalize to get component time series\n",
    "t2s_ts_z = stats.zscore(t2s_ts)\n",
    "s0_ts_z = stats.zscore(s0_ts)\n",
    "p = 0.5  # proportion for combination\n",
    "component = (p * t2s_ts_z) + ((1 - p) * s0_ts_z)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "ax.plot(t2s_ts_z, label=\"T2* fluctuations\", color=\"blue\")\n",
    "ax.plot(s0_ts_z, label=\"S0 fluctuations\", color=\"red\")\n",
    "ax.plot(component, label=\"Component\", color=\"black\", alpha=0.5, linewidth=5)\n",
    "ax.set_xlim(0, n_trs - 1)\n",
    "ax.set_xlabel(\"Time (TR)\")\n",
    "leg = ax.legend(fontsize=14, ncol=3)\n",
    "glue(\"fig_component_curves\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32d7f3",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_component_curves\n",
    ":name: fig_component_curves\n",
    ":align: center\n",
    "\n",
    "Now let's apply this approach to components\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5ef8d",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "interval = int(np.floor(n_echoes / 7))\n",
    "echoes_to_plot = list(range(5, n_echoes, interval))\n",
    "fig, axes = plt.subplots(\n",
    "    len(echoes_to_plot), sharex=True, sharey=False, figsize=(14, 6)\n",
    ")\n",
    "\n",
    "for i_echo, echo in enumerate(echoes_to_plot):\n",
    "    axes[i_echo].plot(multiecho_signal[echo, :], color=pal[i_echo])\n",
    "    axes[i_echo].set_ylabel(\n",
    "        \"{0}ms\".format(echo_times[echo]),\n",
    "        rotation=0,\n",
    "        va=\"center\",\n",
    "        ha=\"right\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    axes[i_echo].set_yticks([])\n",
    "    axes[i_echo].set_xticks([])\n",
    "\n",
    "axes[-1].set_xlabel(\"Time\", fontsize=16)\n",
    "axes[-1].set_xlim(0, n_trs - 1)\n",
    "glue(\"fig_component_curves_2\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ed0da",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_component_curves_2\n",
    ":name: fig_component_curves_2\n",
    ":align: center\n",
    "\n",
    "Now let's apply this approach to components again.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e169e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "interval = int(np.floor(n_echoes / 7))\n",
    "echoes_to_plot = list(range(5, n_echoes, interval))\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "for i_echo, echo in enumerate(echoes_to_plot):\n",
    "    rep_echo_times = np.ones(n_trs) * echo\n",
    "    ax.scatter(rep_echo_times, multiecho_signal[echo, :], alpha=0.05, color=pal[i_echo])\n",
    "\n",
    "max_signal = np.max(multiecho_signal, axis=1)\n",
    "min_signal = np.min(multiecho_signal, axis=1)\n",
    "ax.fill_between(echo_times, max_signal, min_signal, alpha=0.2)\n",
    "\n",
    "ax.set_ylabel(\"BOLD signal\", fontsize=16)\n",
    "ax.set_xlabel(\"Echo Time (ms)\", fontsize=16)\n",
    "ax.set_xticks(echoes_to_plot)\n",
    "ax.set_xlim(0, np.max(echo_times))\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "fig.tight_layout()\n",
    "glue(\"fig_component_curves_3\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2db519",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_component_curves_3\n",
    ":name: fig_component_curves_3\n",
    ":align: center\n",
    "\n",
    "Now let's apply this approach to components again.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe890c9",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "\n",
    "# Add a constant term to the array\n",
    "comp_X = np.hstack((component[:, None], np.ones((component.shape[0], 1))))\n",
    "pes, _, _, _ = np.linalg.lstsq(comp_X, multiecho_signal.T, rcond=None)\n",
    "pes = pes[0, :]\n",
    "\n",
    "F_S0, F_R2, pred_S0, pred_R2 = compute_te_dependence_statistics(\n",
    "    multiecho_signal, pes, echo_times\n",
    ")\n",
    "ax.plot(echo_times, pred_R2, label=\"Predicted T2* model values\", c=\"blue\")\n",
    "ax.plot(echo_times, pred_S0, label=\"Predicted S0 model values\", c=\"red\")\n",
    "ax.plot(echo_times, pes, label=\"Component PEs\", alpha=0.5, linewidth=5, c=\"black\")\n",
    "ax.plot(echo_times, pred_R2, label=r\"$\\kappa$ = {:.02f}\".format(F_R2[0]), alpha=0)\n",
    "ax.plot(echo_times, pred_S0, label=r\"$\\rho$ = {:.02f}\".format(F_S0[0]), alpha=0)\n",
    "ax.set_xlim(0, np.max(echo_times))\n",
    "ax.set_xlabel(\"Echo time (ms)\")\n",
    "leg = ax.legend(fontsize=14, ncol=2)\n",
    "glue(\"fig_component_curves_4\", fig, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd10da",
   "metadata": {},
   "source": [
    "```{glue:figure} fig_component_curves_4\n",
    ":name: fig_component_curves_4\n",
    ":align: center\n",
    "\n",
    "Now let's apply this approach to components again.\n",
    "```\n",
    "\n",
    "```{prf:algorithm} Minimum image regression\n",
    ":label: minimum-image-regression\n",
    "<!-- Written by Taylor Salo, Jessica Bartley, and Elizabeth DuPre -->\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "- $\\mathbf{O}$ is the matrix of optimally combined (OC) data, of shape $v \\times t$,\n",
    "where $v$ is the number of voxels in the brain mask and $t$ is the number of timepoints in the scan.\n",
    "- $\\mathbf{M}$ is the mixing matrix from the ICA decomposition, of shape $c \\times t$, where $c$ is the number of components.\n",
    "- $W$ is the set of indices of all components in $\\mathbf{M}$: $W = \\{1, 2, 3, ..., c\\}$\n",
    "- $N$ is the set of indices of all non-ignored components (i.e., all accepted or BOLD-like, and rejected or non-BOLD components) in\n",
    "  $\\mathbf{M}$: $N \\in \\mathbb{N}^k \\text{ s.t } 1 \\leq k \\leq c, N \\subseteq W$\n",
    "- $A$ is the set of indices of all accepted (i.e., BOLD-like) components in $\\mathbf{M}$:\n",
    "  $A \\in \\mathbb{N}^l \\text{ s.t } 1 \\leq l \\leq k, A \\subseteq N$\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "- Multi-echo denoised data without the T1-like effect, referred to as $\\mathbf{D}$ or MEDN+MIR.\n",
    "- Multi-echo BOLD-like data without the T1-like effect, referred to as $\\mathbf{H}$ or MEHK+MIR.\n",
    "- ICA mixing matrix with the T1-like effect removed from component time series ($\\mathbf{K}$).\n",
    "- Map of the T1-like effect ($\\mathbf{m}$)\n",
    "\n",
    "**Algorithm**\n",
    "\n",
    "1.  The voxel-wise means ($\\mathbf{\\overline{O}} \\in \\mathbb{R}^{v}$) and standard deviations\n",
    "    ($\\mathbf{\\sigma_{O}} \\in \\mathbb{R}^{v}$) of the optimally combined data are computed over time.\n",
    "2.  The optimally combined data are z-normalized over time ($\\mathbf{O_z} \\in \\mathbb{R}^{v \\times t}$).\n",
    "3.  The normalized optimally combined data matrix ($\\mathbf{O_z}$) is regressed on the ICA mixing matrix\n",
    "    ($\\mathbf{M} \\in \\mathbb{R}^{c \\times t}$) to construct component-wise parameter estimate maps\n",
    "    ($\\mathbf{B} \\in \\mathbb{R}^{v \\times c}$).\n",
    "\n",
    "    <!-- no intercept included, because unnecessary and data are normalized. -->\n",
    "    $$\n",
    "        \\mathbf{O_{z}} = \\mathbf{B} \\mathbf{M} + \\mathbf{\\epsilon}, \\enspace \\mathbf{\\epsilon} \\in \\mathbb{R}^{v \\times t}\n",
    "    $$\n",
    "\n",
    "4.  $N$ is used to select rows from the mixing matrix $\\mathbf{M}$ and columns from the parameter estimate matrix $\\mathbf{B}$\n",
    "    that correspond to non-ignored (i.e., accepted and rejected) components, forming reduced matrices $\\mathbf{M}_N$ and $\\mathbf{B}_N$.\n",
    "    The normalized time series matrix for the combined ignored components and variance left unexplained by the ICA decomposition is then\n",
    "    computed by subtracting the scalar product of the non-ignored beta weight and mixing matrices from the normalized OC data time series\n",
    "    ($\\mathbf{O_{z}}$).\n",
    "    The result is referred to as the normalized residuals time series matrix ($\\mathbf{R} \\in \\mathbb{R}^{v \\times t}$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{R} = \\mathbf{O_{z}} - \\mathbf{B}_N \\mathbf{M}_N, \\enspace \\mathbf{B}_N \\in \\mathbb{R}^{v \\times |N|},\n",
    "        \\enspace \\mathbf{M}_N \\in \\mathbb{R}^{|N| \\times t}\n",
    "    $$\n",
    "\n",
    "5.  We can likewise construct the normalized time series of BOLD-like components ($\\mathbf{P} \\in \\mathbb{R}^{v \\times t}$) by\n",
    "    multiplying similarly reduced parameter estimate and mixing matrices composed of only the columns and rows, respectively,\n",
    "    that are associated with the accepted components indexed in $A$.\n",
    "    The resulting time series matrix is similar to the time series matrix referred to elsewhere in the manuscript as\n",
    "    multi-echo high-Kappa (MEHK), with the exception that the component time series have been normalized prior to reconstruction.\n",
    "\n",
    "    $$\n",
    "        \\mathbf{P} = \\mathbf{B}_A \\mathbf{M}_A, \\enspace \\mathbf{B}_A \\in \\mathbb{R}^{v \\times |A|},\n",
    "        \\enspace \\mathbf{M}_A \\in \\mathbb{R}^{|A| \\times t}\n",
    "    $$\n",
    "\n",
    "6.  The map of the T1-like effect ($\\mathbf{m} \\in \\mathbb{R}^{v}$) is constructed by taking the minimum across timepoints\n",
    "    from the normalized MEHK time series ($\\mathbf{P}$) and then mean-centering across brain voxels.\n",
    "    Let $J = \\{1, ..., t\\}$ denote the indices of the columns of matrix $\\mathbf{P}$, and let $p_{ij}$ denote the value of the\n",
    "    element $\\mathbf{P}[i,j]$.\n",
    "\n",
    "    <!-- adapted from https://math.stackexchange.com/a/871689 -->\n",
    "    $$\n",
    "        \\mathbf{q_{i}} = \\min_{j\\in{J}}p_{ij} \\quad \\forall  i = 1,...,v\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "        \\mathbf{m} = \\mathbf{q} - \\mathbf{\\overline{q}}, \\enspace \\mathbf{q} \\in \\mathbb{R}^{v}\n",
    "    $$\n",
    "\n",
    "7.  The standardized optimally combined time series matrix ($\\mathbf{O_z}$) is regressed on the T1-like effect map\n",
    "    ($\\mathbf{m}$) to estimate the volume-wise global signal time series ($\\mathbf{g} \\in \\mathbb{R}^t$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{O_{z}} = \\mathbf{m} \\otimes \\mathbf{g} + \\mathbf{\\epsilon}, \\enspace \\mathbf{\\epsilon} \\in \\mathbb{R}^{v \\times t}\n",
    "    $$\n",
    "\n",
    "    Where $\\otimes$ is the outer product.\n",
    "\n",
    "8.  The normalized BOLD time series matrix ($\\mathbf{P}$) is then regressed on this global signal time series ($\\mathbf{g}$)\n",
    "    in order to estimate a global signal map ($\\mathbf{s} \\in \\mathbb{R}^v$) and the normalized BOLD time series matrix without\n",
    "    the T1-like effect ($\\mathbf{E} \\in \\mathbb{R}^{v \\times t}$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{P} = \\mathbf{g} \\otimes \\mathbf{s} + \\mathbf{E}\n",
    "    $$\n",
    "\n",
    "9.  The time series matrix of BOLD-like components without the T1-like effect (MEHK+MIR, $\\mathbf{H} \\in \\mathbb{R}^{v \\times t}$),\n",
    "    scaled to match the original OC time series matrix, is constructed by multiplying each column of $\\mathbf{E}$ by the vector\n",
    "    $\\mathbf{\\sigma_{O}}$.\n",
    "\n",
    "    $$\n",
    "        \\mathbf{H} = \\mathbf{E} \\circ\n",
    "        \\underbrace{\n",
    "            \\pmatrix{\n",
    "                \\mathbf{{\\sigma_{O}}_1} & \\cdots & \\mathbf{{\\sigma_{O}}_1}\\\\\n",
    "                \\vdots & \\vdots & \\vdots \\\\\n",
    "                \\mathbf{{\\sigma_{O}}_v} & \\cdots & \\mathbf{{\\sigma_{O}}_v}\\\\\n",
    "            }\n",
    "        }_{t}\n",
    "    $$\n",
    "\n",
    "    Where $\\circ$ is the [Hadamard product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices))\n",
    "    for element-wise multiplication of two matrices.\n",
    "\n",
    "10. The ICA-denoised time series without the T1-like effect (MEDN+MIR, $\\mathbf{D} \\in \\mathbb{R}^{v \\times t}$)\n",
    "    is constructed by adding the residuals time series ($\\mathbf{R}$) to the normalized BOLD time series ($\\mathbf{E}$),\n",
    "    multiplying each column of the result by the vector $\\sigma_{O}$, and adding back in the voxel-wise mean of the OC time series\n",
    "    ($\\mathbf{\\overline{O}}$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{D} = \\mathbf{\\overline{O}} + (\\mathbf{E} + \\mathbf{R}) \\circ\n",
    "        \\underbrace{\n",
    "            \\pmatrix{\n",
    "                \\mathbf{{\\sigma_{O}}_1} & \\cdots & \\mathbf{{\\sigma_{O}}_1}\\\\\n",
    "                \\vdots & \\vdots & \\vdots \\\\\n",
    "                \\mathbf{{\\sigma_{O}}_v} & \\cdots & \\mathbf{{\\sigma_{O}}_v}\\\\\n",
    "            }\n",
    "        }_{t}\n",
    "    $$\n",
    "\n",
    "11. The T1c-corrected ICA mixing matrix is then derived by regressing the global signal time series $\\mathbf{g}$ from\n",
    "    each component's time series. Let $\\mathbf{Q}$ be the associated parameter estimate matrix\n",
    "    ($\\mathbf{Q} \\in \\mathbb{R}^{c \\times t}$).\n",
    "\n",
    "    $$\n",
    "        \\mathbf{M} = \\mathbf{Q}\\mathbf{g} + \\mathbf{K}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "        \\mathbf{K} = \\mathbf{M} - \\mathbf{Q}\\mathbf{g}\n",
    "    $$\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "source_map": [
   12,
   49,
   76,
   103,
   107,
   196,
   273,
   279,
   285,
   313,
   323,
   348,
   392,
   401,
   407,
   411,
   477,
   486,
   509,
   518,
   538,
   547,
   568
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}